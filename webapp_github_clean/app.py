import streamlit as st
import sys
import os
import cv2
import numpy as np
import torch
import torchvision.transforms as T
from PIL import Image
from torch.utils.data import DataLoader, Dataset
import traceback
import datetime
import json
import pandas as pd
from pathlib import Path
import gdown
from streamlit_image_zoom import image_zoom

# ============================================================
# 1. THI·∫æT L·∫¨P M√îI TR∆Ø·ªúNG & IMPORT CONFIG
# ============================================================
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

try:
    import config
except ImportError:
    st.error("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file config.py.")
    st.stop()

sys.path.append(str(config.SRC_DIR))

# --- C·∫§U H√åNH TRANG WEB ---
st.set_page_config(
    page_title=config.APP_TITLE,
    page_icon=config.APP_ICON,
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
        .stApp {background-color: #f8f9fa;}
        div[data-testid="stMetricValue"] {font-size: 1.1rem; font-weight: bold;}
        div[data-testid="stDataFrame"] {font-size: 0.85rem;}
        .block-container {padding-top: 2rem;}
        /* Style cho ph·∫ßn gi·ªõi thi·ªáu t√°c gi·∫£ - Fix l·ªói xu·ªëng d√≤ng */
        .author-box {
            background-color: #e3f2fd;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            border-left: 4px solid #1976d2;
            font-size: 0.9rem;
            line-height: 1.5;
        }
    </style>
""", unsafe_allow_html=True)

# ============================================================
# 2. T·∫¢I MODEL & DATASET
# ============================================================
MODEL_DRIVE_ID = "1Ruvjg57t-JLoP1QcWK_I8UzcFuUFjCnN" # ‚ö†Ô∏è Thay ID file .pth c·ªßa b·∫°n v√†o ƒë√¢y

@st.cache_resource
def download_model_from_drive():
    if not config.MODEL_PATH.exists():
        config.MODELS_DIR.mkdir(parents=True, exist_ok=True)
        url = f'https://drive.google.com/uc?id={MODEL_DRIVE_ID}'
        output = str(config.MODEL_PATH)
        st.toast("‚è≥ ƒêang t·∫£i Model t·ª´ Cloud...", icon="‚òÅÔ∏è")
        try:
            gdown.download(url, output, quiet=False)
            st.success("‚úÖ T·∫£i Model th√†nh c√¥ng!")
        except Exception as e:
            st.error(f"‚ùå L·ªói t·∫£i model: {e}")
            st.stop()

class WSIPatchDataset(Dataset):
    def __init__(self, image, coords, patch_size=50, transform=None):
        self.image = image; self.coords = coords; self.patch_size = patch_size; self.transform = transform
    def __len__(self): return len(self.coords)
    def __getitem__(self, idx):
        y, x = self.coords[idx]
        patch = self.image[y : y + self.patch_size, x : x + self.patch_size]
        if patch.shape[0] != self.patch_size or patch.shape[1] != self.patch_size:
            patch = cv2.resize(patch, (self.patch_size, self.patch_size))
        if self.transform: patch = self.transform(patch)
        return patch

@st.cache_resource
def load_model(device_name):
    download_model_from_drive()
    device = torch.device(device_name)
    try:
        from src.model_hybrid1 import CNNDeiTSmall
        model = CNNDeiTSmall(**config.MODEL_PARAMS)
        if not config.MODEL_PATH.exists(): return None
        checkpoint = torch.load(config.MODEL_PATH, map_location=device)
        state_dict = checkpoint['model_state'] if 'model_state' in checkpoint else checkpoint
        model.load_state_dict(state_dict, strict=False)
        model.to(device)
        model.eval()
        return model
    except Exception as e: return None

def generate_tissue_mask(img_rgb):
    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
    lower_white = np.array([0, 0, 230]); upper_white = np.array([180, 25, 255]) 
    mask_white = cv2.inRange(img_hsv, lower_white, upper_white)
    tissue_mask = cv2.bitwise_not(mask_white)
    kernel = np.ones((5,5), np.uint8)
    tissue_mask = cv2.dilate(tissue_mask, kernel, iterations=1)
    return tissue_mask

def run_inference(model, image_array, device, threshold, batch_size, max_patches, stride, progress_bar):
    h, w = image_array.shape[:2]
    patch_size = config.PATCH_SIZE
    
    # 1. T·∫°o mask & t·ªça ƒë·ªô
    tissue_mask = generate_tissue_mask(image_array)
    coords = []
    
    # D√πng stride ƒë·ªông t·ª´ tham s·ªë truy·ªÅn v√†o
    for y in range(0, h - patch_size + 1, stride):
        for x in range(0, w - patch_size + 1, stride):
            mask_roi = tissue_mask[y : y + patch_size, x : x + patch_size]
            if cv2.countNonZero(mask_roi) / (patch_size**2) > 0.05:
                coords.append((y, x))
    
    if not coords: return None, None, {"cancer_percentage": 0.0}

    total_found = len(coords)
    if max_patches > 0 and total_found > max_patches:
        coords = coords[:max_patches]
        st.toast(f"‚ö° Demo Mode: {max_patches}/{total_found} patches", icon="üöÄ")

    # 2. DataLoader
    transform = T.Compose([T.ToPILImage(), T.Resize(config.MODEL_PARAMS['img_size']), T.ToTensor(), T.Normalize(mean=config.NORMALIZE_MEAN, std=config.NORMALIZE_STD)])
    dataset = WSIPatchDataset(image_array, coords, patch_size, transform)
    num_workers = 0 if os.name == 'nt' else config.NUM_WORKERS
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)
    
    # 3. Inference Loop
    # D√πng ma tr·∫≠n c·ªông d·ªìn ƒë·ªÉ l√†m m·ªãn heatmap (Probability Accumulation)
    prob_map = np.zeros((h, w), dtype=np.float32)
    count_map = np.zeros((h, w), dtype=np.float32)

    all_confidences = []
    
    with torch.no_grad():
        batch_start_idx = 0
        for i, batch in enumerate(loader):
            batch = batch.to(device)
            outputs = model(batch)
            probs = torch.softmax(outputs, dim=1)[:, 1] # X√°c su·∫•t l·ªõp ung th∆∞
            probs_np = probs.cpu().numpy()
            
            all_confidences.extend(probs_np)
            
            # Map l·∫°i v√†o ·∫£nh g·ªëc (C·ªông d·ªìn ƒë·ªÉ x·ª≠ l√Ω v√πng ch·ªìng l·∫•n)
            current_batch_size = len(probs_np)
            batch_coords = coords[batch_start_idx : batch_start_idx + current_batch_size]
            
            for (y, x), p in zip(batch_coords, probs_np):
                prob_map[y:y+patch_size, x:x+patch_size] += p
                count_map[y:y+patch_size, x:x+patch_size] += 1
            
            batch_start_idx += current_batch_size
            
            if progress_bar: progress_bar.progress((i+1)/len(loader), text=f"Processing batch {i+1}/{len(loader)}...")

    # 4. T√≠nh trung b√¨nh Heatmap (L√†m m·ªãn)
    # Tr√°nh chia cho 0
    avg_heatmap = np.divide(prob_map, count_map, out=np.zeros_like(prob_map), where=count_map!=0)

    # 5. T·∫°o Overlay th√¥ng minh (V√πng ƒë·∫∑c)
    overlay = image_array.copy()
    
    # T·∫°o mask nh·ªã ph√¢n t·ª´ heatmap ƒë√£ l√†m m·ªãn
    binary_mask = (avg_heatmap >= threshold).astype(np.uint8)
    
    # D√πng thu·∫≠t to√°n h√¨nh th√°i h·ªçc (Morphology) ƒë·ªÉ l√†m li·ªÅn m·∫°ch c√°c v√πng ƒë·ª©t g√£y nh·ªè
    kernel_smooth = np.ones((5,5), np.uint8)
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel_smooth)
    
    # T√¥ m√†u ƒë·ªè l√™n v√πng mask = 1
    # T·∫°o l·ªõp m√†u ƒë·ªè
    red_layer = np.zeros_like(overlay)
    red_layer[:] = [255, 0, 0] # ƒê·ªè to√†n b·ªô
    
    # Ch·ªâ √°p d·ª•ng ·ªü n∆°i c√≥ mask
    mask_indices = binary_mask == 1
    if np.any(mask_indices):
        # Blend m√†u ƒë·ªè v√†o ·∫£nh g·ªëc (Transparency 40%)
        overlay[mask_indices] = cv2.addWeighted(overlay[mask_indices], 0.6, red_layer[mask_indices], 0.4, 0)
        
        # V·∫Ω vi·ªÅn bao quanh v√πng b·ªánh (Contour) ƒë·ªÉ n·ªïi b·∫≠t h∆°n
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(overlay, contours, -1, (200, 0, 0), 2)

    # Th·ªëng k√™
    # T√≠nh di·ªán t√≠ch pixel thay v√¨ patch ƒë·∫øm s·ªë (ch√≠nh x√°c h∆°n v·ªõi overlap)
    total_tissue_pixels = np.count_nonzero(count_map)
    cancer_pixels = np.count_nonzero(binary_mask)
    
    cancer_percentage = 0.0
    if total_tissue_pixels > 0:
        cancer_percentage = round((cancer_pixels / total_tissue_pixels) * 100, 2)
            
    stats = {
        "total_patches": len(coords), 
        "original_patches": total_found, 
        "cancer_patches": int(np.sum(np.array(all_confidences) >= threshold)), # ƒê·∫øm s·ªë patch raw
        "cancer_percentage": cancer_percentage,
        "max_confidence": round(float(np.max(all_confidences)), 4) if all_confidences else 0
    }
    return overlay, avg_heatmap, stats

# ============================================================
# 4. GIAO DI·ªÜN CH√çNH (MAIN)
# ============================================================
def main():
    if 'analysis_result' not in st.session_state: st.session_state.analysis_result = None
    if 'history' not in st.session_state: st.session_state.history = []

    # === SIDEBAR ===
    with st.sidebar:
        if config.LOGO_PATH.exists(): st.image(str(config.LOGO_PATH), width=120)
        
        # --- HI·ªÇN TH·ªä M√î T·∫¢ (ƒê√É S·ª¨A L·ªñI XU·ªêNG D√íNG) ---
        desc_html = config.APP_DESCRIPTION.strip().replace('\n', '<br>')
        st.markdown(f'<div class="author-box">{desc_html}</div>', unsafe_allow_html=True)
        # -----------------------------------------------

        st.header("‚öôÔ∏è C·∫•u h√¨nh")
        dev_show = "GPU (CUDA)" if torch.cuda.is_available() else "CPU"
        st.info(f"Thi·∫øt b·ªã: **{dev_show}**")

        with st.expander("üõ†Ô∏è Chi ti·∫øt & T·ªëi ∆∞u", expanded=False):
            st.markdown(f"**Hybrid CNN-DeiT** (Patches: {config.PATCH_SIZE}px)")
            if config.MODEL_VIZ_PATH.exists(): st.image(str(config.MODEL_VIZ_PATH), caption="Ki·∫øn tr√∫c", use_column_width=True)
            
            ui_max_patches = st.slider("Gi·ªõi h·∫°n Patch (Demo)", 0, 5000, 0, 100)
            
            # --- T√çNH NƒÇNG M·ªöI: ƒê·ªò M·ªäN (STRIDE) ---
            st.markdown("---")
            ui_stride = st.select_slider(
                "ƒê·ªô m·ªãn (Stride)", 
                options=[10, 25, 50], 
                value=25,
                help="10: R·∫•t m·ªãn (Ch·∫≠m). 25: M·ªãn v·ª´a (Chu·∫©n). 50: Nhanh (Th√¥)."
            )

        ui_threshold = st.slider("Ng∆∞·ª°ng (Threshold)", 0.0, 1.0, config.CONFIDENCE_THRESHOLD, 0.05)
        ui_batch_size = st.selectbox("Batch Size", [16, 32, 64, 128, 256], index=3 if config.DEVICE=="cuda" else 1)

        # L·ªäCH S·ª¨
        if st.session_state.history:
            st.markdown("---")
            st.subheader("üïí L·ªãch s·ª≠ phi√™n")
            st.dataframe(pd.DataFrame(st.session_state.history), hide_index=True, height=150)

        # C√îNG C·ª§ B√ÅO C√ÅO
        st.markdown("---")
        with st.expander("üìä C√¥ng c·ª• B√°o c√°o", expanded=False):
            if st.button("üìë T·ªïng h·ª£p CSV & Xem", use_container_width=True):
                results_dir = config.BASE_DIR / "results"
                csv_files = list(results_dir.glob("stats_*.csv")) if results_dir.exists() else []
                if not csv_files:
                    st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu.")
                else:
                    try:
                        df_list = [pd.read_csv(f) for f in csv_files if "summary" not in f.name]
                        if df_list:
                            combined_df = pd.concat(df_list, ignore_index=True)
                            if 'timestamp' in combined_df.columns:
                                combined_df = combined_df.sort_values(by='timestamp', ascending=False)
                            
                            summary_path = results_dir / "summary_report.csv"
                            combined_df.to_csv(summary_path, index=False)
                            st.success(f"ƒê√£ g·ªôp {len(df_list)} file!")
                            
                            def highlight(val): return 'background-color: #ffcccc' if val >= config.DANGER_THRESHOLD_PERCENT else ''
                            cols = [c for c in ['image_name', 'cancer_percentage', 'max_confidence', 'timestamp'] if c in combined_df.columns]
                            st.dataframe(combined_df[cols].style.map(highlight, subset=['cancer_percentage'] if 'cancer_percentage' in combined_df else None), hide_index=True)
                            
                            with open(summary_path, "rb") as f:
                                st.download_button("‚¨áÔ∏è T·∫£i file CSV", f, "summary_report.csv", "text/csv")
                    except Exception as e: st.error(f"L·ªói: {e}")

            if st.button("üóëÔ∏è X√≥a to√†n b·ªô l·ªãch s·ª≠", type="primary"):
                results_dir = config.BASE_DIR / "results"
                if results_dir.exists():
                    shutil.rmtree(results_dir); results_dir.mkdir()
                    st.session_state.history = []; st.session_state.analysis_result = None
                    st.rerun()

    # === MAIN CONTENT ===
    st.title(config.APP_TITLE)
    st.write("---")

    col1, col2 = st.columns([1, 1.5])
    
    with col1:
        st.subheader("1. Ch·ªçn d·ªØ li·ªáu")
        input_method = st.radio("Ngu·ªìn:", ["T·∫£i ·∫£nh l√™n", "D√πng ·∫£nh m·∫´u"], horizontal=True)
        uploaded_file = None; current_img_name = ""

        if input_method == "T·∫£i ·∫£nh l√™n":
            uploaded_file = st.file_uploader("Upload", type=["jpg", "png", "jpeg"])
            if uploaded_file:
                image_pil = Image.open(uploaded_file).convert('RGB')
                current_img_name = uploaded_file.name
        elif hasattr(config, 'SAMPLE_IMAGES'):
            sample_choice = st.selectbox("M·∫´u:", list(config.SAMPLE_IMAGES.keys()))
            sample_path = config.SAMPLE_IMAGES[sample_choice]
            if sample_path.exists():
                image_pil = Image.open(sample_path).convert('RGB')
                current_img_name = sample_path.name
                class Mock: name=current_img_name
                uploaded_file = Mock()

        if 'image_pil' in locals() and image_pil:
            image_array = np.array(image_pil)
            st.image(image_pil, caption=f"·∫¢nh: {current_img_name}", use_column_width=True)
            analyze = st.button("üöÄ PH√ÇN T√çCH NGAY", type="primary", use_container_width=True)
        else: analyze = False

    with col2:
        st.subheader("2. K·∫øt qu·∫£")
        if analyze and image_pil:
            progress = st.progress(0, text="Kh·ªüi t·∫°o...")
            try:
                run_device = "cuda" if torch.cuda.is_available() else "cpu"
                model = load_model(run_device)
                if model:
                    # Truy·ªÅn th√™m tham s·ªë ui_stride
                    overlay, heatmap, stats = run_inference(
                        model, image_array, run_device, 
                        ui_threshold, ui_batch_size, ui_max_patches, ui_stride, progress
                    )
                    progress.empty()
                    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                    st.session_state.analysis_result = {'overlay': overlay, 'heatmap': heatmap, 'stats': stats, 'filename': current_img_name, 'timestamp': ts}
                    st.session_state.history.insert(0, {"Time": datetime.datetime.now().strftime("%H:%M"), "File": current_img_name, "Risk": f"{stats['cancer_percentage']}%"})
            except Exception as e: st.error("L·ªói h·ªá th·ªëng."); st.code(traceback.format_exc())

        res = st.session_state.analysis_result
        if res and res.get('filename') == current_img_name:
            overlay, heatmap, stats, ts = res['overlay'], res['heatmap'], res['stats'], res['timestamp']
            
            # TABS HI·ªÇN TH·ªä
            t1, t2 = st.tabs(["üîç Soi v√πng b·ªánh", "üå°Ô∏è Heatmap"])
            
            hm_vis = (np.clip(heatmap, 0, 1) * 255).astype(np.uint8)
            hm_color = cv2.cvtColor(cv2.applyColorMap(hm_vis, cv2.COLORMAP_JET), cv2.COLOR_BGR2RGB)
            blend = cv2.addWeighted(image_array, 0.6, hm_color, 0.4, 0)

            with t1: 
                st.caption("Di chu·ªôt ƒë·ªÉ ph√≥ng to:")
                image_zoom(Image.fromarray(overlay), mode="mousemove", size=700, zoom_factor=3)
            with t2: 
                st.caption("Di chu·ªôt ƒë·ªÉ ph√≥ng to:")
                image_zoom(Image.fromarray(blend), mode="mousemove", size=700, zoom_factor=3)
            
            # L∆∞u file & Hi·ªÉn th·ªã Metrics
            r_dir = config.BASE_DIR / "results"
            r_dir.mkdir(exist_ok=True)
            p_csv = r_dir / f"stats_{ts}.csv"
            
            if not p_csv.exists():
                    try:
                        cv2.imwrite(str(r_dir/f"overlay_{ts}.png"), cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))
                        s_csv = stats.copy()
                        s_csv.update({'timestamp': ts, 'image_name': current_img_name, 'stride': ui_stride})
                        pd.DataFrame([s_csv]).to_csv(p_csv, index=False)
                    except: pass

            st.divider()
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("T·ªïng Patch", stats['total_patches'])
            c2.metric("IDC Patch", stats['cancer_patches'])
            clr = "inverse" if stats['cancer_percentage'] >= config.DANGER_THRESHOLD_PERCENT else "normal"
            c3.metric("T·ª∑ l·ªá b·ªánh", f"{stats['cancer_percentage']}%", delta_color=clr)
            c4.metric("Max Conf", stats['max_confidence'])

            if stats['cancer_percentage'] >= config.DANGER_THRESHOLD_PERCENT: st.error(f"üö® NGUY C∆† CAO ({stats['cancer_percentage']}%)")
            else: st.success("‚úÖ AN TO√ÄN")

            if st.button("üîÑ Reset", type="secondary", use_container_width=True):
                st.session_state.analysis_result = None; st.rerun()

if __name__ == "__main__":
    main()